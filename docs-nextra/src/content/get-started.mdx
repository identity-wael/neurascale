import { Steps, Tabs, Callout } from 'nextra/components'

# Get Started

This guide will help you get up and running with NeuraScale in minutes.

## Prerequisites

Before you begin, ensure you have the following installed:

### Core Requirements
- **Python** 3.12.11 (exact version required) - [Download](https://www.python.org/downloads/)
- **Node.js** 18.x or higher - [Download](https://nodejs.org/)
- **pnpm** 9.x or higher - [Installation guide](https://pnpm.io/installation)
- **Docker** & Docker Compose - [Download](https://www.docker.com/)
- **Git** - [Download](https://git-scm.com/)

### For GCP Deployment
- **Google Cloud SDK** - [Installation guide](https://cloud.google.com/sdk/docs/install)
- **Terraform** 1.5.x or higher - [Download](https://www.terraform.io/downloads)
- **kubectl** - [Installation guide](https://kubernetes.io/docs/tasks/tools/)
- **Helm** 3.x - [Installation guide](https://helm.sh/docs/intro/install/)

<Callout type="warning">
  Python version must be exactly 3.12.11. Other versions may cause compatibility issues.
</Callout>

### GCP Setup

<Steps>
### Install Google Cloud SDK

<Tabs items={['macOS', 'Linux', 'Windows']}>
  <Tabs.Tab>
    ```bash
    # Using Homebrew
    brew install --cask google-cloud-sdk

    # Or download from https://cloud.google.com/sdk/docs/install
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```bash
    # Add the Cloud SDK distribution URI as a package source
    echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main" | sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list

    # Import the Google Cloud public key
    curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key --keyring /usr/share/keyrings/cloud.google.gpg add -

    # Update and install the SDK
    sudo apt-get update && sudo apt-get install google-cloud-cli
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    Download and run the installer from: https://cloud.google.com/sdk/docs/install#windows
  </Tabs.Tab>
</Tabs>

### Authenticate with GCP

```bash
# Login to GCP
gcloud auth login

# Set default project (use your environment)
gcloud config set project development-neurascale

# Configure application default credentials
gcloud auth application-default login
```

### Install Terraform

<Tabs items={['macOS', 'Linux', 'Windows']}>
  <Tabs.Tab>
    ```bash
    # Using Homebrew
    brew install terraform

    # Verify installation
    terraform --version
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```bash
    # Add HashiCorp GPG key
    wget -O- https://apt.releases.hashicorp.com/gpg | sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg

    # Add HashiCorp repo
    echo "deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main" | sudo tee /etc/apt/sources.list.d/hashicorp.list

    # Install Terraform
    sudo apt update && sudo apt install terraform
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    Download from: https://www.terraform.io/downloads

    Or use Chocolatey:
    ```powershell
    choco install terraform
    ```
  </Tabs.Tab>
</Tabs>

### Configure GCP Permissions

Ensure your GCP account has the following roles:
- `roles/owner` or `roles/editor` for development
- `roles/iam.serviceAccountUser` for service account impersonation
- `roles/storage.admin` for Terraform state management

For production deployments, use the service account:
```bash
gcloud iam service-accounts keys create ~/key.json \
  --iam-account=github-actions@neurascale.iam.gserviceaccount.com

export GOOGLE_APPLICATION_CREDENTIALS=~/key.json
```
</Steps>

## Quick Start

<Steps>
### Clone the Repository

```bash
git clone https://github.com/identity-wael/neurascale.git
cd neurascale
```

### Set Up Virtual Environments

Run our automated setup script to configure Python environments:

```bash
./scripts/dev-tools/setup-venvs.sh
```

This script will:
- Verify Python 3.12.11 is available
- Create virtual environments for all components
- Install required dependencies

### Start Infrastructure Services

Choose your deployment method:

**Local Development**

Launch the required infrastructure services locally:

```bash
docker-compose up -d
```

This starts:
- TimescaleDB for time-series data
- Redis for caching and real-time features
- PostgreSQL for application data
- MCP Server for AI assistant integration

**GCP Deployment**

For production GCP deployment, we use a multi-environment Terraform setup:

```bash
cd neural-engine/terraform

# Initialize with environment-specific backend
terraform init -backend-config=backend-configs/development.hcl

# Plan with environment variables
terraform plan -var-file="environments/development.tfvars"

# Apply infrastructure
terraform apply -var-file="environments/development.tfvars"
```

**GCP Resources Created:**
- **Bigtable**: For high-performance time-series neural data storage
- **Pub/Sub**: Topics and subscriptions for each signal type (EEG, EMG, etc.)
- **Cloud Run**: MCP Server deployment
- **Artifact Registry**: Docker image storage
- **Cloud SQL**: PostgreSQL for metadata and session data
- **Secret Manager**: API keys and sensitive configuration
- **GKE**: Kubernetes cluster for Neural Engine (production only)

### Start the Neural Engine

<Tabs items={['Development', 'Staging', 'Production']}>
  <Tabs.Tab>
    ```bash
    cd neural-engine
    source venv/bin/activate
    python -m src.main
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```bash
    cd neural-engine
    source venv/bin/activate
    # Configure for staging environment
    export ENV=staging
    export GCP_PROJECT=staging-neurascale
    uvicorn src.main:app --host 0.0.0.0 --port 8000 --workers 2
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```bash
    cd neural-engine
    source venv/bin/activate
    # Configure for production environment
    export ENV=production
    export GCP_PROJECT=production-neurascale
    uvicorn src.main:app --host 0.0.0.0 --port 8000 --workers 4
    ```
  </Tabs.Tab>
</Tabs>

The Neural Engine API will be available at: http://localhost:8000

### Start the Console (Optional)

In a new terminal:

```bash
cd console
npm run dev
```

The NeuraScale Console will be available at: http://localhost:3000

### Test Your Installation

Create a synthetic device to verify everything is working:

```bash
# Create a test device
curl -X POST http://localhost:8000/api/v1/devices \
  -H "Content-Type: application/json" \
  -d '{"device_id": "test-device", "device_type": "synthetic"}'

# Start streaming data
curl -X POST http://localhost:8000/api/v1/devices/test-device/stream/start
```

You should see synthetic neural data streaming in the logs.
</Steps>

## Deployment Environments

NeuraScale uses a multi-environment GCP setup:

| Environment | Project ID | Branch | Purpose |
|------------|------------|--------|---------|
| Development | `development-neurascale` | `develop` | Feature development and testing |
| Staging | `staging-neurascale` | PR branches | Integration testing and validation |
| Production | `production-neurascale` | `main` | Live production environment |

Each environment has:
- Isolated GCP project with separate billing
- Environment-specific Terraform state in GCS
- Automated deployment via GitHub Actions
- Cross-project IAM for service accounts

## Project Structure

```
neurascale/
├── neural-engine/           # Core neural data processing engine
│   ├── src/
│   │   ├── api/            # FastAPI endpoints
│   │   ├── devices/        # Device interfaces (OpenBCI, Emotiv, etc.)
│   │   ├── processing/     # Signal processing pipelines
│   │   ├── classification/ # Real-time ML models
│   │   └── neural_ledger/  # HIPAA-compliant audit trail
│   ├── terraform/          # GCP infrastructure as code
│   │   ├── modules/        # Reusable Terraform modules
│   │   │   ├── neural-ingestion/  # Pub/Sub, Bigtable, Cloud Functions
│   │   │   ├── mcp-server/        # Cloud Run MCP deployment
│   │   │   ├── networking/        # VPC and service connections
│   │   │   ├── gke/              # Kubernetes cluster config
│   │   │   └── database/          # Cloud SQL, Redis, BigQuery
│   │   ├── environments/   # Environment-specific configs
│   │   └── backend-configs/# Terraform state backends
│   └── tests/              # Test suite
├── console/                # NeuraScale Console UI
├── docs-nextra/           # Documentation (you are here!)
├── infrastructure/        # Kubernetes & deployment configs
│   ├── cross-project-iam/ # IAM setup across GCP projects
│   └── k8s/              # Kubernetes manifests
├── kubernetes/            # Helm charts
│   └── helm/neural-engine/# Neural Engine Helm chart
├── mcp-server/           # Model Context Protocol server
└── scripts/              # Development tools and utilities
```

## Next Steps

Now that you have NeuraScale running, explore:

<div className="nx-grid nx-mt-6 nx-gap-4 md:nx-grid-cols-2">
  <div className="nx-border nx-border-gray-200 dark:nx-border-gray-800 nx-rounded-lg nx-p-4">
    <h3 className="nx-font-semibold nx-mb-2">Connect a Device</h3>
    <div className="nx-text-sm nx-text-gray-600 dark:nx-text-gray-400 nx-mb-2">
      Learn how to connect real BCI devices
    </div>
    <a href="/docs/device-integration" className="nx-text-primary-600 nx-text-sm">
      Device Integration →
    </a>
  </div>

  <div className="nx-border nx-border-gray-200 dark:nx-border-gray-800 nx-rounded-lg nx-p-4">
    <h3 className="nx-font-semibold nx-mb-2">Build Your First App</h3>
    <div className="nx-text-sm nx-text-gray-600 dark:nx-text-gray-400 nx-mb-2">
      Create a simple BCI application
    </div>
    <a href="/docs/tutorials/first-app" className="nx-text-primary-600 nx-text-sm">
      Tutorial →
    </a>
  </div>

  <div className="nx-border nx-border-gray-200 dark:nx-border-gray-800 nx-rounded-lg nx-p-4">
    <h3 className="nx-font-semibold nx-mb-2">API Reference</h3>
    <div className="nx-text-sm nx-text-gray-600 dark:nx-text-gray-400 nx-mb-2">
      Explore the complete API documentation
    </div>
    <a href="/docs/api" className="nx-text-primary-600 nx-text-sm">
      API Docs →
    </a>
  </div>

  <div className="nx-border nx-border-gray-200 dark:nx-border-gray-800 nx-rounded-lg nx-p-4">
    <h3 className="nx-font-semibold nx-mb-2">Architecture Deep Dive</h3>
    <div className="nx-text-sm nx-text-gray-600 dark:nx-text-gray-400 nx-mb-2">
      Understand the system architecture
    </div>
    <a href="/docs/architecture" className="nx-text-primary-600 nx-text-sm">
      Architecture →
    </a>
  </div>
</div>

## Common Commands

<Tabs items={['Neural Engine', 'Neural CLI', 'Development', 'Docker']}>
  <Tabs.Tab>
    ```bash
    # Activate virtual environment
    source neural-engine/venv/bin/activate

    # Start the engine
    python -m src.main

    # Run tests
    pytest tests/

    # Format code
    black .

    # Lint code
    flake8 .

    # Type checking
    mypy .
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```bash
    # Using Docker
    docker run --rm --network neural-engine_neural-net \
      neurascale/neural-cli:latest list-devices

    # List active streams
    docker run --rm --network neural-engine_neural-net \
      neurascale/neural-cli:latest list-streams

    # Monitor device
    docker run --rm --network neural-engine_neural-net \
      neurascale/neural-cli:latest monitor --device-id test-device

    # View audit trail
    docker run --rm --network neural-engine_neural-net \
      neurascale/neural-cli:latest audit --last 100
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```bash
    # Install dependencies
    pnpm install

    # Start development server
    pnpm dev

    # Build for production
    pnpm build

    # Run linting
    pnpm lint

    # Format code
    pnpm format
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```bash
    # Start all services
    docker-compose up -d

    # View logs
    docker-compose logs -f

    # Stop services
    docker-compose down

    # Clean volumes
    docker-compose down -v

    # Deploy to GKE using Helm
    helm upgrade --install neural-engine \
      kubernetes/helm/neural-engine/ \
      --values kubernetes/helm/neural-engine/values.yaml \
      --namespace neural-engine \
      --create-namespace
    ```
  </Tabs.Tab>
</Tabs>

## Troubleshooting

<Callout type="error" title="Port Already in Use">
  If you see "Port 3000/8000 is already in use":

  ```bash
  # Find and kill the process
  lsof -ti:3000 | xargs kill -9
  # Or use a different port
  PORT=3001 npm run dev
  ```
</Callout>

<Callout type="error" title="Python Version Issues">
  If you encounter Python version errors:

  ```bash
  # Check your Python version
  python --version

  # Must be exactly 3.12.11
  # Run the setup script to fix
  ./scripts/dev-tools/setup-venvs.sh
  ```
</Callout>

<Callout type="info">
  For more troubleshooting help, see our [Troubleshooting Guide](/docs/troubleshooting) or ask in [GitHub Discussions](https://github.com/identity-wael/neurascale/discussions).
</Callout>

## Getting Help

- **Documentation**: [docs.neurascale.io](https://docs.neurascale.io)
- **GitHub Discussions**: [Ask questions](https://github.com/identity-wael/neurascale/discussions)
- **Issue Tracker**: [Report bugs](https://github.com/identity-wael/neurascale/issues)
- **Email Support**: [support@neurascale.io](mailto:support@neurascale.io)

Ready to build something amazing? Let's bridge mind and world together!
