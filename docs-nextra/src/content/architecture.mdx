import { Tabs, Callout, Table } from 'nextra/components'

export const StatusBadge = ({ status }) => {
  const colors = {
    'available': 'nx-bg-green-100 nx-text-green-800 dark:nx-bg-green-900 dark:nx-text-green-200',
    'beta': 'nx-bg-blue-100 nx-text-blue-800 dark:nx-bg-blue-900 dark:nx-text-blue-200',
    'coming-soon': 'nx-bg-yellow-100 nx-text-yellow-800 dark:nx-bg-yellow-900 dark:nx-text-yellow-200',
    'planned': 'nx-bg-gray-100 nx-text-gray-800 dark:nx-bg-gray-900 dark:nx-text-gray-200'
  }
  return (
    <span className={`nx-inline-flex nx-items-center nx-px-2.5 nx-py-0.5 nx-rounded-full nx-text-xs nx-font-medium ${colors[status] || colors.planned}`}>
      {status === 'available' && 'âœ“ Available'}
      {status === 'beta' && 'ðŸ”§ Beta'}
      {status === 'coming-soon' && 'ðŸš€ Coming Soon'}
      {status === 'planned' && 'ðŸ“… Planned'}
    </span>
  )
}

# Architecture

NeuraScale is a modern BCI platform with a decoupled architecture that separates the user-facing console from the neural data processing engine. The platform combines best-in-class cloud services for optimal performance, security, and developer experience.

## Core Architecture Components

1. **Console (Frontend)** - Next.js application deployed on Vercel for the user interface
2. **Authentication** - Firebase Auth for secure user authentication and session management
3. **User Database** - NeonDB (PostgreSQL) for user data, settings, and session metadata
4. **Neural Engine** - Python-based backend for real-time BCI data processing
5. **API Gateway** - RESTful and WebSocket APIs connecting frontend to backend services

## Implementation Status

<div className="nx-mt-6">
  <table className="nx-w-full nx-table-auto nx-border-collapse">
    <thead>
      <tr className="nx-border-b nx-border-gray-200 dark:nx-border-gray-800">
        <th className="nx-text-left nx-p-2">Component</th>
        <th className="nx-text-left nx-p-2">Status</th>
        <th className="nx-text-left nx-p-2">Notes</th>
      </tr>
    </thead>
    <tbody>
      <tr className="nx-border-b nx-border-gray-200 dark:nx-border-gray-800">
        <td className="nx-p-2"><strong>Frontend Console</strong></td>
        <td className="nx-p-2"><StatusBadge status="beta" /></td>
        <td className="nx-p-2 nx-text-sm">Core UI deployed on Vercel, active development</td>
      </tr>
      <tr className="nx-border-b nx-border-gray-200 dark:nx-border-gray-800">
        <td className="nx-p-2"><strong>Firebase Auth</strong></td>
        <td className="nx-p-2"><StatusBadge status="available" /></td>
        <td className="nx-p-2 nx-text-sm">Fully integrated with Google OAuth</td>
      </tr>
      <tr className="nx-border-b nx-border-gray-200 dark:nx-border-gray-800">
        <td className="nx-p-2"><strong>NeonDB</strong></td>
        <td className="nx-p-2"><StatusBadge status="available" /></td>
        <td className="nx-p-2 nx-text-sm">Production database for user data</td>
      </tr>
      <tr className="nx-border-b nx-border-gray-200 dark:nx-border-gray-800">
        <td className="nx-p-2"><strong>Neural Engine Core</strong></td>
        <td className="nx-p-2"><StatusBadge status="available" /></td>
        <td className="nx-p-2 nx-text-sm">Device management, signal processing framework</td>
      </tr>
      <tr className="nx-border-b nx-border-gray-200 dark:nx-border-gray-800">
        <td className="nx-p-2"><strong>REST API</strong></td>
        <td className="nx-p-2"><StatusBadge status="available" /></td>
        <td className="nx-p-2 nx-text-sm">Device control and data access endpoints</td>
      </tr>
      <tr className="nx-border-b nx-border-gray-200 dark:nx-border-gray-800">
        <td className="nx-p-2"><strong>WebSocket API</strong></td>
        <td className="nx-p-2"><StatusBadge status="beta" /></td>
        <td className="nx-p-2 nx-text-sm">Real-time streaming in development</td>
      </tr>
      <tr className="nx-border-b nx-border-gray-200 dark:nx-border-gray-800">
        <td className="nx-p-2"><strong>ML Pipeline</strong></td>
        <td className="nx-p-2"><StatusBadge status="coming-soon" /></td>
        <td className="nx-p-2 nx-text-sm">Model framework ready, training models</td>
      </tr>
      <tr className="nx-border-b nx-border-gray-200 dark:nx-border-gray-800">
        <td className="nx-p-2"><strong>Cloud Deployment</strong></td>
        <td className="nx-p-2"><StatusBadge status="coming-soon" /></td>
        <td className="nx-p-2 nx-text-sm">GCP infrastructure being configured</td>
      </tr>
      <tr className="nx-border-b nx-border-gray-200 dark:nx-border-gray-800">
        <td className="nx-p-2"><strong>TimescaleDB</strong></td>
        <td className="nx-p-2"><StatusBadge status="planned" /></td>
        <td className="nx-p-2 nx-text-sm">Time-series storage for neural data</td>
      </tr>
      <tr className="nx-border-b nx-border-gray-200 dark:nx-border-gray-800">
        <td className="nx-p-2"><strong>BigQuery Analytics</strong></td>
        <td className="nx-p-2"><StatusBadge status="planned" /></td>
        <td className="nx-p-2 nx-text-sm">Large-scale data analysis platform</td>
      </tr>
    </tbody>
  </table>
</div>

<Callout type="info">
  The platform is under active development with core functionality available for testing. Production deployment with full cloud infrastructure coming soon.
</Callout>

## System Architecture

```mermaid
graph TB
    subgraph "User Layer"
        U1[Web Browser]
        U2[Mobile App]
        U3[Desktop App]
    end

    subgraph "Frontend - Vercel"
        subgraph "NeuraScale Console"
            NC1[Next.js App<br/>React â€¢ TypeScript]
            NC2[UI Components<br/>Tailwind â€¢ shadcn/ui]
            NC3[State Management<br/>Zustand â€¢ React Query]
            NC4[Real-time Updates<br/>Socket.io Client]
        end
        V1[Vercel Edge Network<br/>Global CDN â€¢ Edge Functions]
    end

    subgraph "Authentication - Firebase"
        FB1[Firebase Auth<br/>OAuth Providers]
        FB2[User Management<br/>Profiles â€¢ Permissions]
        FB3[Session Tokens<br/>JWT â€¢ Refresh Tokens]
    end

    subgraph "User Data - NeonDB"
        subgraph "PostgreSQL Database"
            ND1[User Profiles<br/>Settings â€¢ Preferences]
            ND2[Session Metadata<br/>Experiments â€¢ Results]
            ND3[Device Configs<br/>Saved Configurations]
            ND4[Analysis History<br/>Reports â€¢ Exports]
        end
        NP1[Neon Proxy<br/>Connection Pooling]
        NP2[Neon Autoscaling<br/>Compute â€¢ Storage]
    end

    subgraph "API Gateway"
        AG1[REST API<br/>Express â€¢ Node.js]
        AG2[WebSocket Server<br/>Real-time Streams]
        AG3[GraphQL API<br/>Query Optimization]
    end

    subgraph "Neural Engine Backend"
        subgraph "Device Service"
            DS1[Device Manager]
            DS2[Discovery Engine]
            DS3[Health Monitor]
        end

        subgraph "Processing Service"
            PS1[Signal Pipeline]
            PS2[Feature Extraction]
            PS3[ML Inference]
        end

        subgraph "Data Service"
            DTS1[Time Series API]
            DTS2[Storage API]
            DTS3[Analytics API]
        end
    end

    subgraph "Neural Data Storage"
        NS1[TimescaleDB<br/>Time Series Data]
        NS2[Redis<br/>Real-time Cache]
        NS3[Cloud Storage<br/>Raw EEG Files]
        NS4[PostgreSQL<br/>Analysis Results]
    end

    U1 --> V1
    U2 --> V1
    U3 --> V1

    V1 --> NC1
    NC1 --> NC2
    NC1 --> NC3
    NC1 --> NC4

    NC1 --> FB1
    FB1 --> FB2
    FB2 --> FB3

    NC1 --> NP1
    NP1 --> ND1
    NP1 --> ND2
    NP1 --> ND3
    NP1 --> ND4

    NC1 --> AG1
    NC4 --> AG2
    NC1 --> AG3

    AG1 --> DS1
    AG2 --> PS1
    AG3 --> DTS1

    DS1 --> NS2
    PS1 --> NS1
    DTS1 --> NS3
    DTS1 --> NS4

    style U1 fill:#e3f2fd,color:#0d47a1
    style U2 fill:#e3f2fd,color:#0d47a1
    style U3 fill:#e3f2fd,color:#0d47a1
    style V1 fill:#000000,color:#ffffff
    style NC1 fill:#0070f3,color:#ffffff
    style NC2 fill:#0070f3,color:#ffffff
    style NC3 fill:#0070f3,color:#ffffff
    style NC4 fill:#0070f3,color:#ffffff
    style FB1 fill:#ffa000,color:#ffffff
    style FB2 fill:#ffa000,color:#ffffff
    style FB3 fill:#ffa000,color:#ffffff
    style ND1 fill:#00e5a0,color:#000000
    style ND2 fill:#00e5a0,color:#000000
    style ND3 fill:#00e5a0,color:#000000
    style ND4 fill:#00e5a0,color:#000000
    style NP1 fill:#00e5a0,color:#000000
    style NP2 fill:#00e5a0,color:#000000
    style AG1 fill:#6b7280,color:#ffffff
    style AG2 fill:#6b7280,color:#ffffff
    style AG3 fill:#6b7280,color:#ffffff
    style DS1 fill:#8b5cf6,color:#ffffff
    style PS1 fill:#8b5cf6,color:#ffffff
    style DTS1 fill:#8b5cf6,color:#ffffff
    style NS1 fill:#3b82f6,color:#ffffff
    style NS2 fill:#ef4444,color:#ffffff
    style NS3 fill:#10b981,color:#ffffff
    style NS4 fill:#3b82f6,color:#ffffff
```

## Frontend Architecture (Console)

### Vercel Deployment

The NeuraScale Console is a modern web application built with Next.js and deployed on Vercel's edge network for optimal performance and global availability.

```mermaid
graph LR
    subgraph "Vercel Infrastructure"
        VE[Edge Network<br/>150+ PoPs Globally]
        VF[Edge Functions<br/>API Routes]
        VS[Static Assets<br/>Immutable Deployments]
        VC[Edge Config<br/>Feature Flags]
    end

    subgraph "Console Features"
        CF1[Dashboard<br/>Real-time Monitoring]
        CF2[Device Control<br/>Configuration UI]
        CF3[Data Visualization<br/>Charts & Graphs]
        CF4[Session Management<br/>Recording Controls]
        CF5[Analysis Tools<br/>Export & Reports]
    end

    subgraph "Build Pipeline"
        GH[GitHub<br/>Source Control]
        VA[Vercel Analytics<br/>Web Vitals]
        VB[Build System<br/>Next.js Compiler]
        VP[Preview Deployments<br/>PR Integration]
    end

    GH --> VB
    VB --> VS
    VB --> VF
    VS --> VE
    VF --> VE

    VE --> CF1
    VE --> CF2
    VE --> CF3
    VE --> CF4
    VE --> CF5

    CF1 --> VA
    CF2 --> VA
    CF3 --> VA

    style VE fill:#000000,color:#ffffff
    style VF fill:#000000,color:#ffffff
    style VS fill:#000000,color:#ffffff
    style VC fill:#000000,color:#ffffff
    style GH fill:#24292e,color:#ffffff
    style VA fill:#0070f3,color:#ffffff
    style VB fill:#0070f3,color:#ffffff
    style VP fill:#0070f3,color:#ffffff
```

**Key Benefits:**
- Zero-config deployments with Git integration
- Automatic HTTPS and custom domains
- Edge caching and global CDN
- Serverless functions for API routes
- Built-in analytics and monitoring

### Firebase Authentication

Firebase provides secure, scalable authentication with support for multiple identity providers and seamless integration with the frontend.

```mermaid
graph TB
    subgraph "Identity Providers"
        IP1[Google OAuth]
        IP2[GitHub OAuth]
        IP3[Email/Password]
        IP4[Magic Links]
    end

    subgraph "Firebase Auth"
        FA1[Authentication SDK<br/>Client Libraries]
        FA2[User Management<br/>Admin SDK]
        FA3[Security Rules<br/>Access Control]
        FA4[Custom Claims<br/>Role-Based Access]
    end

    subgraph "Integration Points"
        INT1[Next.js Middleware<br/>Route Protection]
        INT2[API Authentication<br/>Token Verification]
        INT3[Session Management<br/>Refresh Tokens]
        INT4[User Context<br/>React Hooks]
    end

    IP1 --> FA1
    IP2 --> FA1
    IP3 --> FA1
    IP4 --> FA1

    FA1 --> FA2
    FA2 --> FA3
    FA3 --> FA4

    FA1 --> INT1
    FA1 --> INT2
    FA1 --> INT3
    FA1 --> INT4

    style IP1 fill:#4285f4,color:#ffffff
    style IP2 fill:#24292e,color:#ffffff
    style IP3 fill:#ea4335,color:#ffffff
    style IP4 fill:#34a853,color:#ffffff
    style FA1 fill:#ffa000,color:#ffffff
    style FA2 fill:#ffa000,color:#ffffff
    style FA3 fill:#ffa000,color:#ffffff
    style FA4 fill:#ffa000,color:#ffffff
```

### NeonDB (User Data Storage)

NeonDB provides a serverless PostgreSQL database optimized for modern applications with automatic scaling and branching capabilities.

```mermaid
graph LR
    subgraph "NeonDB Features"
        NF1[Serverless PostgreSQL<br/>Auto-scaling]
        NF2[Database Branching<br/>Dev/Test Environments]
        NF3[Point-in-Time Recovery<br/>7-day History]
        NF4[Connection Pooling<br/>PgBouncer Built-in]
    end

    subgraph "Data Models"
        subgraph "User Tables"
            UT1[users<br/>Profiles & Settings]
            UT2[organizations<br/>Team Management]
            UT3[api_keys<br/>Access Tokens]
        end

        subgraph "Session Tables"
            ST1[experiments<br/>Session Metadata]
            ST2[recordings<br/>File References]
            ST3[analyses<br/>Results & Reports]
        end

        subgraph "Configuration Tables"
            CT1[device_configs<br/>Saved Settings]
            CT2[processing_pipelines<br/>Custom Workflows]
            CT3[ml_models<br/>User Models]
        end
    end

    subgraph "Access Patterns"
        AP1[Prisma ORM<br/>Type-safe Queries]
        AP2[Connection Pool<br/>Supavisor]
        AP3[Read Replicas<br/>Analytics Queries]
    end

    NF1 --> NF4
    NF2 --> NF3

    AP1 --> UT1
    AP1 --> ST1
    AP1 --> CT1

    AP2 --> AP1
    AP3 --> ST1

    style NF1 fill:#00e5a0,color:#000000
    style NF2 fill:#00e5a0,color:#000000
    style NF3 fill:#00e5a0,color:#000000
    style NF4 fill:#00e5a0,color:#000000
    style AP1 fill:#2d3748,color:#ffffff
    style AP2 fill:#2d3748,color:#ffffff
    style AP3 fill:#2d3748,color:#ffffff
```

## Backend Architecture (Neural Engine)

### Device Service

The Device Service manages all BCI device connections and real-time data acquisition.

```mermaid
graph LR
    subgraph "Device Service Architecture"
        DR[Device Registry<br/>PostgreSQL]
        CP[Connection Pool<br/>Async Manager]
        SE[Streaming Engine<br/>Ring Buffers]
        HM[Health Monitor<br/>Prometheus]
        PS[Pub/Sub Client<br/>Publisher]
    end

    subgraph "Supported Devices"
        subgraph "Consumer BCIs"
            D1[OpenBCI<br/>Cyton/Ganglion]
            D2[Emotiv<br/>EPOC+/Insight]
            D3[Muse<br/>Muse 2/S]
            D4[NeuroSky<br/>MindWave]
        end

        subgraph "Research Systems"
            D5[g.tec<br/>g.USBamp]
            D6[BrainProducts<br/>actiCHamp]
            D7[ANT Neuro<br/>eegoâ„¢]
            D8[BioSemi<br/>ActiveTwo]
        end

        subgraph "Clinical Arrays"
            D9[Blackrock<br/>Utah Array]
            D10[Plexon<br/>OmniPlex]
            D11[Custom LSL<br/>Lab Streaming]
        end
    end

    subgraph "Device Features"
        F1[Auto-Discovery<br/>mDNS/USB]
        F2[Retry Logic<br/>Exponential Backoff]
        F3[Impedance Check<br/>Real-time]
        F4[Signal Quality<br/>SNR Monitoring]
        F5[Multi-device Sync<br/>NTP/PTP]
        F6[Hot Swap<br/>Zero Downtime]
    end

    D1 --> DR
    D2 --> DR
    D3 --> DR
    D4 --> DR
    D5 --> DR
    D6 --> DR
    D7 --> DR
    D8 --> DR
    D9 --> DR
    D10 --> DR
    D11 --> DR

    DR --> CP
    CP --> SE
    SE --> HM
    SE --> PS
    PS -.-> |"Topics:<br/>device.connected<br/>device.data<br/>device.status"| PubSub[Cloud Pub/Sub]

    HM --> F1
    HM --> F2
    HM --> F3
    HM --> F4
    HM --> F5
    HM --> F6

    style DR fill:#ea4335,color:#ffffff
    style CP fill:#ea4335,color:#ffffff
    style SE fill:#ea4335,color:#ffffff
    style HM fill:#ea4335,color:#ffffff
    style PS fill:#ea4335,color:#ffffff
    style PubSub fill:#fbbc04,color:#000000
    style D1 fill:#e3f2fd,color:#0d47a1
    style D2 fill:#e3f2fd,color:#0d47a1
    style D3 fill:#e3f2fd,color:#0d47a1
    style D4 fill:#e3f2fd,color:#0d47a1
    style D5 fill:#e8f5e9,color:#1b5e20
    style D6 fill:#e8f5e9,color:#1b5e20
    style D7 fill:#e8f5e9,color:#1b5e20
    style D8 fill:#e8f5e9,color:#1b5e20
    style D9 fill:#fce4ec,color:#880e4f
    style D10 fill:#fce4ec,color:#880e4f
    style D11 fill:#fce4ec,color:#880e4f
```

**Technical Specifications:**
- Written in Python 3.12 with asyncio
- Uses lock-free ring buffers for data
- Implements backpressure mechanisms
- Sub-100ms latency guarantee

### Processing Service

The Processing Service handles all signal processing and feature extraction operations using GCP AI/ML services.

```mermaid
graph TB
    subgraph "Input Stream"
        PS1[Pub/Sub<br/>device.data]
        PS2[Stream Processing<br/>Dataflow]
    end

    subgraph "Real-Time Processing Pipeline"
        subgraph "Preprocessing (NumPy/SciPy)"
            PP1[Resampler<br/>Anti-aliasing]
            PP2[Filter Bank<br/>Butterworth/Chebyshev]
            PP3[Artifact Removal<br/>ICA/ASR]
            PP4[Windowing<br/>Sliding/Overlapping]
        end

        subgraph "Feature Extraction (MNE-Python)"
            FE1[Spectral Features<br/>FFT, PSD, Wavelets]
            FE2[Temporal Features<br/>Statistics, Entropy, Hjorth]
            FE3[Connectivity Metrics<br/>Coherence, PLV, PAC]
            FE4[Time-Frequency<br/>STFT, Morlet Wavelets]
        end

        subgraph "ML Pipeline (Vertex AI)"
            ML1[Feature Store<br/>Vector Database]
            ML2[AutoML Models<br/>Tabular Classification]
            ML3[Custom Models<br/>TensorFlow/PyTorch]
            ML4[Model Serving<br/>Vertex Endpoints]
        end

        subgraph "Classification Tasks"
            C1[Mental State<br/>Focus/Relaxation]
            C2[Sleep Staging<br/>NREM/REM/Wake]
            C3[Motor Imagery<br/>Left/Right Hand]
            C4[Seizure Prediction<br/>Pre-ictal Detection]
            C5[Cognitive Load<br/>Working Memory]
        end
    end

    subgraph "Output"
        OUT1[Pub/Sub<br/>processing.results]
        OUT2[Cloud SQL<br/>Session Metadata]
        OUT3[BigQuery<br/>Analytics & ML Data]
    end

    PS1 --> PS2
    PS2 --> PP1

    PP1 --> PP2
    PP2 --> PP3
    PP3 --> PP4

    PP4 --> FE1
    PP4 --> FE2
    PP4 --> FE3
    PP4 --> FE4

    FE1 --> ML1
    FE2 --> ML1
    FE3 --> ML1
    FE4 --> ML1

    ML1 --> ML2
    ML1 --> ML3
    ML2 --> ML4
    ML3 --> ML4

    ML4 --> C1
    ML4 --> C2
    ML4 --> C3
    ML4 --> C4
    ML4 --> C5

    C1 --> OUT1
    C2 --> OUT1
    C3 --> OUT1
    C4 --> OUT1
    C5 --> OUT1

    FE1 --> OUT2
    FE2 --> OUT2
    FE3 --> OUT2
    FE4 --> OUT2

    OUT1 --> OUT3

    style PS1 fill:#fbbc04,color:#000000
    style PS2 fill:#fbbc04,color:#000000
    style PP1 fill:#4285f4,color:#ffffff
    style PP2 fill:#4285f4,color:#ffffff
    style PP3 fill:#4285f4,color:#ffffff
    style PP4 fill:#4285f4,color:#ffffff
    style FE1 fill:#34a853,color:#ffffff
    style FE2 fill:#34a853,color:#ffffff
    style FE3 fill:#34a853,color:#ffffff
    style FE4 fill:#34a853,color:#ffffff
    style ML1 fill:#ea4335,color:#ffffff
    style ML2 fill:#ea4335,color:#ffffff
    style ML3 fill:#ea4335,color:#ffffff
    style ML4 fill:#ea4335,color:#ffffff
    style C1 fill:#9c27b0,color:#ffffff
    style C2 fill:#9c27b0,color:#ffffff
    style C3 fill:#9c27b0,color:#ffffff
    style C4 fill:#9c27b0,color:#ffffff
    style C5 fill:#9c27b0,color:#ffffff
    style OUT1 fill:#fbbc04,color:#000000
    style OUT2 fill:#4285f4,color:#ffffff
    style OUT3 fill:#4285f4,color:#ffffff
```

### Data Service

The Data Service manages data persistence, retrieval, and analytics using GCP's multi-tier storage architecture.

```mermaid
graph LR
    subgraph "Data Ingestion"
        IN1[Pub/Sub<br/>Real-time Stream]
        IN2[Dataflow<br/>ETL Pipeline]
        IN3[Transfer Service<br/>Batch Import]
    end

    subgraph "Multi-Tier Storage Architecture"
        subgraph "Hot Tier (Real-time)"
            H1[Memorystore Redis<br/>Session Cache<br/>Sub-ms Access]
            H2[Cloud SQL<br/>Active Sessions<br/>5-10ms Access]
        end

        subgraph "Analytics Tier"
            W1[BigQuery Streaming<br/>Real-time Ingestion<br/>Neural Metrics]
            W2[Cloud SQL<br/>Metadata & Config<br/>PostgreSQL HA]
        end

        subgraph "Archive Tier"
            C1[Cloud Storage<br/>Raw Data Export<br/>Nearline/Coldline]
            C2[BigQuery<br/>Historical Analytics<br/>Partitioned Tables]
            C3[Backup Storage<br/>Disaster Recovery<br/>Multi-region]
        end
    end

    subgraph "Data Access Patterns"
        AP1[Direct API<br/>Low Latency]
        AP2[Batch Export<br/>CSV/Parquet]
        AP3[BigQuery ML<br/>Analytics]
        AP4[Dataproc<br/>Spark/Hadoop]
    end

    IN1 --> H1
    IN1 --> H2
    IN2 --> W1
    IN3 --> C1

    H1 --> W1
    H2 --> W1
    W1 --> C1
    W2 --> C2
    C1 --> C2
    C2 --> C3

    H1 --> AP1
    H2 --> AP1
    W1 --> AP1
    C2 --> AP3
    C1 --> AP2
    C2 --> AP4

    style IN1 fill:#fbbc04,color:#000000
    style IN2 fill:#fbbc04,color:#000000
    style IN3 fill:#fbbc04,color:#000000
    style H1 fill:#ea4335,color:#ffffff
    style H2 fill:#ea4335,color:#ffffff
    style W1 fill:#4285f4,color:#ffffff
    style W2 fill:#4285f4,color:#ffffff
    style C1 fill:#34a853,color:#ffffff
    style C2 fill:#34a853,color:#ffffff
    style C3 fill:#34a853,color:#ffffff
    style AP1 fill:#9c27b0,color:#ffffff
    style AP2 fill:#9c27b0,color:#ffffff
    style AP3 fill:#9c27b0,color:#ffffff
    style AP4 fill:#9c27b0,color:#ffffff
```

<Callout type="info">
  **Current Implementation**: The production system currently uses Cloud SQL PostgreSQL for metadata and BigQuery for analytics. Bigtable integration is planned for future releases when sub-millisecond latency is required for massive time-series datasets.
</Callout>

## Data Flow & Latency

### Real-Time Data Pipeline

```mermaid
graph LR
    subgraph "Device Layer"
        D1[OpenBCI<br/>Cyton]
        D2[Emotiv<br/>EPOC+]
        D3[Clinical<br/>Arrays]
        D4[Custom<br/>LSL]
    end

    subgraph "Acquisition & Publishing"
        A1[Device Manager<br/>GKE Pod]
        A2[Protocol Handler<br/>Python Async]
        A3[Publisher Client<br/>Pub/Sub SDK]
    end

    subgraph "Cloud Pub/Sub Topics"
        T1[device.connected<br/>Control Plane]
        T2[device.data.raw<br/>250-1000 Hz Stream]
        T3[device.status<br/>Health Metrics]
        T4[device.impedance<br/>Quality Check]
    end

    subgraph "Stream Processing"
        SP1[Dataflow Job<br/>Apache Beam]
        SP2[Windowing<br/>1s Tumbling]
        SP3[Aggregation<br/>Statistics]
    end

    subgraph "Processing Topics"
        T5[processing.features<br/>Extracted Features]
        T6[processing.results<br/>Classifications]
        T7[processing.alerts<br/>Anomalies]
    end

    subgraph "Storage Sinks"
        S1[Bigtable<br/>Raw Data]
        S2[BigQuery<br/>Analytics]
        S3[Cloud Storage<br/>Archive]
        S4[Monitoring<br/>Metrics]
    end

    subgraph "API Layer"
        API1[Cloud Run<br/>REST API]
        API2[WebSocket<br/>Real-time]
        API3[gRPC<br/>Low Latency]
    end

    D1 --> A1
    D2 --> A1
    D3 --> A1
    D4 --> A1

    A1 --> A2
    A2 --> A3

    A3 --> T1
    A3 --> T2
    A3 --> T3
    A3 --> T4

    T2 --> SP1
    SP1 --> SP2
    SP2 --> SP3

    SP3 --> T5
    SP3 --> T6
    SP3 --> T7

    T2 --> S1
    T5 --> S2
    T6 --> S2
    T7 --> S4
    SP3 --> S3

    S1 --> API1
    S2 --> API2
    T6 --> API3

    style D1 fill:#e3f2fd,color:#0d47a1
    style D2 fill:#e3f2fd,color:#0d47a1
    style D3 fill:#e3f2fd,color:#0d47a1
    style D4 fill:#e3f2fd,color:#0d47a1
    style A1 fill:#ea4335,color:#ffffff
    style A2 fill:#ea4335,color:#ffffff
    style A3 fill:#ea4335,color:#ffffff
    style T1 fill:#fbbc04,color:#000000
    style T2 fill:#fbbc04,color:#000000
    style T3 fill:#fbbc04,color:#000000
    style T4 fill:#fbbc04,color:#000000
    style T5 fill:#fbbc04,color:#000000
    style T6 fill:#fbbc04,color:#000000
    style T7 fill:#fbbc04,color:#000000
    style SP1 fill:#34a853,color:#ffffff
    style SP2 fill:#34a853,color:#ffffff
    style SP3 fill:#34a853,color:#ffffff
    style S1 fill:#4285f4,color:#ffffff
    style S2 fill:#4285f4,color:#ffffff
    style S3 fill:#4285f4,color:#ffffff
    style S4 fill:#4285f4,color:#ffffff
    style API1 fill:#9c27b0,color:#ffffff
    style API2 fill:#9c27b0,color:#ffffff
    style API3 fill:#9c27b0,color:#ffffff
```

### Latency Budget

<Table>
  <thead>
    <Table.Tr>
      <Table.Th>Stage</Table.Th>
      <Table.Th>Budget</Table.Th>
      <Table.Th>Actual</Table.Th>
      <Table.Th>Notes</Table.Th>
    </Table.Tr>
  </thead>
  <tbody>
    <Table.Tr>
      <Table.Td>Device Acquisition</Table.Td>
      <Table.Td>20ms</Table.Td>
      <Table.Td>10-15ms</Table.Td>
      <Table.Td>Hardware dependent</Table.Td>
    </Table.Tr>
    <Table.Tr>
      <Table.Td>Network Transfer</Table.Td>
      <Table.Td>15ms</Table.Td>
      <Table.Td>5-10ms</Table.Td>
      <Table.Td>Optimized protocols</Table.Td>
    </Table.Tr>
    <Table.Tr>
      <Table.Td>Buffering</Table.Td>
      <Table.Td>5ms</Table.Td>
      <Table.Td>&lt;2ms</Table.Td>
      <Table.Td>Lock-free queues</Table.Td>
    </Table.Tr>
    <Table.Tr>
      <Table.Td>Feature Extraction</Table.Td>
      <Table.Td>15ms</Table.Td>
      <Table.Td>10-15ms</Table.Td>
      <Table.Td>SIMD optimized</Table.Td>
    </Table.Tr>
    <Table.Tr>
      <Table.Td>ML Classification</Table.Td>
      <Table.Td>15ms</Table.Td>
      <Table.Td>5-10ms</Table.Td>
      <Table.Td>TensorRT/ONNX</Table.Td>
    </Table.Tr>
    <Table.Tr>
      <Table.Td>Processing</Table.Td>
      <Table.Td>10ms</Table.Td>
      <Table.Td>5-10ms</Table.Td>
      <Table.Td>Parallel pipelines</Table.Td>
    </Table.Tr>
    <Table.Tr>
      <Table.Td>Storage Write</Table.Td>
      <Table.Td>10ms</Table.Td>
      <Table.Td>5-8ms</Table.Td>
      <Table.Td>Async writes</Table.Td>
    </Table.Tr>
    <Table.Tr>
      <Table.Td>API Response</Table.Td>
      <Table.Td>10ms</Table.Td>
      <Table.Td>5-8ms</Table.Td>
      <Table.Td>Cached responses</Table.Td>
    </Table.Tr>
  </tbody>
</Table>

## Scalability

### Horizontal Scaling Architecture

```mermaid
graph TB
    subgraph "External Traffic"
        ET[Cloud Load Balancer<br/>+ Cloud Armor]
    end

    subgraph "GKE Cluster - Regional"
        subgraph "Control Plane"
            CP[Kubernetes API<br/>HA Masters]
            HPA[Horizontal Pod<br/>Autoscaler]
            VPA[Vertical Pod<br/>Autoscaler]
            CA[Cluster<br/>Autoscaler]
        end

        subgraph "Node Pool 1 - General"
            subgraph "Zone A"
                N1A[n2-standard-4<br/>4 vCPU, 16GB RAM]
                P1A[Device Service<br/>2-10 replicas]
                P2A[API Service<br/>3-20 replicas]
            end

            subgraph "Zone B"
                N1B[n2-standard-4<br/>4 vCPU, 16GB RAM]
                P1B[Device Service<br/>2-10 replicas]
                P2B[API Service<br/>3-20 replicas]
            end

            subgraph "Zone C"
                N1C[n2-standard-4<br/>4 vCPU, 16GB RAM]
                P1C[Device Service<br/>2-10 replicas]
                P2C[API Service<br/>3-20 replicas]
            end
        end

        subgraph "Node Pool 2 - ML/GPU"
            subgraph "GPU Zone A"
                N2A[n1-highmem-4<br/>+ T4 GPU]
                P3A[ML Service<br/>1-5 replicas]
            end

            subgraph "GPU Zone B"
                N2B[n1-highmem-4<br/>+ T4 GPU]
                P3B[ML Service<br/>1-5 replicas]
            end
        end

        subgraph "Node Pool 3 - Memory"
            N3[n2-highmem-8<br/>8 vCPU, 64GB RAM]
            P4[Processing Service<br/>2-8 replicas]
        end
    end

    subgraph "Autoscaling Metrics"
        M1[CPU Usage<br/>>70%]
        M2[Memory Usage<br/>>80%]
        M3[Pub/Sub Queue<br/>>1000 msgs]
        M4[Custom Metrics<br/>Device Count]
    end

    subgraph "Managed Services"
        MS1[Cloud SQL<br/>Auto-failover]
        MS2[Bigtable<br/>Auto-scaling]
        MS3[Pub/Sub<br/>Unlimited Scale]
        MS4[Cloud Storage<br/>âˆž Scale]
    end

    ET --> CP
    CP --> HPA
    CP --> VPA
    CP --> CA

    HPA --> P1A
    HPA --> P2A
    HPA --> P3A
    HPA --> P4

    CA --> N1A
    CA --> N1B
    CA --> N1C
    CA --> N2A
    CA --> N2B
    CA --> N3

    M1 --> HPA
    M2 --> HPA
    M3 --> HPA
    M4 --> HPA

    P1A --> MS1
    P2A --> MS2
    P3A --> MS3
    P4 --> MS4

    style ET fill:#34a853,color:#ffffff
    style CP fill:#ea4335,color:#ffffff
    style HPA fill:#fbbc04,color:#000000
    style VPA fill:#fbbc04,color:#000000
    style CA fill:#fbbc04,color:#000000
    style N1A fill:#4285f4,color:#ffffff
    style N1B fill:#4285f4,color:#ffffff
    style N1C fill:#4285f4,color:#ffffff
    style N2A fill:#9c27b0,color:#ffffff
    style N2B fill:#9c27b0,color:#ffffff
    style N3 fill:#4285f4,color:#ffffff
    style MS1 fill:#0f9d58,color:#ffffff
    style MS2 fill:#0f9d58,color:#ffffff
    style MS3 fill:#0f9d58,color:#ffffff
    style MS4 fill:#0f9d58,color:#ffffff
```

### Resource Allocation

<Tabs items={['Device Service', 'Processing Service', 'Data Service']}>
  <Tabs.Tab>
    **Device Service Resources:**
    - CPU: 2-8 cores
    - Memory: 4-16 GB
    - Network: 1-10 Gbps
    - Scaling: By device count
  </Tabs.Tab>

  <Tabs.Tab>
    **Processing Service Resources:**
    - CPU: 8-32 cores
    - Memory: 32-128 GB
    - GPU: Optional (CUDA)
    - Scaling: By channel count
  </Tabs.Tab>

  <Tabs.Tab>
    **Data Service Resources:**
    - CPU: 4-16 cores
    - Memory: 16-64 GB
    - Storage: NVMe SSD
    - Scaling: By write throughput
  </Tabs.Tab>
</Tabs>

## Security Architecture

### Defense in Depth

```mermaid
graph TB
    subgraph "Edge Security"
        ES1[Cloud Armor<br/>DDoS Protection]
        ES2[Cloud CDN<br/>Edge Caching]
        ES3[SSL/TLS Policy<br/>TLS 1.3 Only]
    end

    subgraph "Network Security"
        NS1[VPC Security<br/>Private Google Access]
        NS2[Cloud Firewall<br/>Ingress/Egress Rules]
        NS3[Private Service Connect<br/>Internal Traffic]
        NS4[Cloud NAT<br/>Egress Control]
    end

    subgraph "Identity & Access"
        IA1[Cloud IAM<br/>Service Accounts]
        IA2[Workload Identity<br/>GKE Integration]
        IA3[Binary Authorization<br/>Container Security]
        IA4[Cloud Identity<br/>SSO/MFA]
    end

    subgraph "Data Security"
        DS1[Cloud KMS<br/>Encryption Keys]
        DS2[Secret Manager<br/>API Keys/Creds]
        DS3[Data Loss Prevention<br/>PII Scanning]
        DS4[CMEK<br/>Customer Keys]
    end

    subgraph "Monitoring & Compliance"
        MC1[Cloud Audit Logs<br/>Immutable Trail]
        MC2[Security Command Center<br/>Threat Detection]
        MC3[Cloud Asset Inventory<br/>Resource Tracking]
        MC4[Neural Ledger<br/>HIPAA Audit Trail]
    end

    subgraph "Runtime Security"
        RS1[Container Analysis<br/>Vulnerability Scanning]
        RS2[GKE Security<br/>Pod Security Policy]
        RS3[Istio Service Mesh<br/>mTLS]
        RS4[Cloud Trace<br/>Request Tracking]
    end

    ES1 --> NS1
    ES2 --> NS1
    ES3 --> NS1

    NS1 --> IA1
    NS2 --> IA1
    NS3 --> IA1
    NS4 --> IA1

    IA1 --> DS1
    IA2 --> DS1
    IA3 --> DS1
    IA4 --> DS1

    DS1 --> MC1
    DS2 --> MC1
    DS3 --> MC1
    DS4 --> MC1

    MC1 --> RS1
    MC2 --> RS1
    MC3 --> RS1
    MC4 --> RS1

    style ES1 fill:#ea4335,color:#ffffff
    style ES2 fill:#ea4335,color:#ffffff
    style ES3 fill:#ea4335,color:#ffffff
    style NS1 fill:#fbbc04,color:#000000
    style NS2 fill:#fbbc04,color:#000000
    style NS3 fill:#fbbc04,color:#000000
    style NS4 fill:#fbbc04,color:#000000
    style IA1 fill:#4285f4,color:#ffffff
    style IA2 fill:#4285f4,color:#ffffff
    style IA3 fill:#4285f4,color:#ffffff
    style IA4 fill:#4285f4,color:#ffffff
    style DS1 fill:#34a853,color:#ffffff
    style DS2 fill:#34a853,color:#ffffff
    style DS3 fill:#34a853,color:#ffffff
    style DS4 fill:#34a853,color:#ffffff
    style MC1 fill:#9c27b0,color:#ffffff
    style MC2 fill:#9c27b0,color:#ffffff
    style MC3 fill:#9c27b0,color:#ffffff
    style MC4 fill:#9c27b0,color:#ffffff
    style RS1 fill:#00acc1,color:#ffffff
    style RS2 fill:#00acc1,color:#ffffff
    style RS3 fill:#00acc1,color:#ffffff
    style RS4 fill:#00acc1,color:#ffffff
```

### Compliance Features

<Tabs items={['SOC 2 Type II', 'HIPAA', 'GDPR']}>
  <Tabs.Tab>
    **SOC 2 Type II Certification:**

    **Trust Service Criteria:**
    - **Security**: Firewall protection, intrusion detection, vulnerability scanning
    - **Availability**: 99.9% uptime SLA, redundancy, disaster recovery
    - **Processing Integrity**: Data validation, error handling, quality assurance
    - **Confidentiality**: Encryption, access matrices, secure disposal
    - **Privacy**: Consent management, data subject rights, retention policies

    **Key Controls:**
    - Continuous monitoring and alerting
    - Change management procedures
    - Vendor risk assessments
    - Annual penetration testing
    - Security awareness training
  </Tabs.Tab>

  <Tabs.Tab>
    **HIPAA Compliance:**
    - End-to-end encryption (AES-256)
    - Audit logging with immutability
    - Access controls (RBAC + ABAC)
    - Data retention policies (7 years)
    - Business Associate Agreements
    - Minimum necessary standard
    - Breach notification procedures
    - Physical safeguards for data centers
  </Tabs.Tab>

  <Tabs.Tab>
    **GDPR Compliance:**
    - Consent management
    - Right to deletion
    - Data portability
    - Privacy by design
    - Data minimization
    - Cross-border transfer controls
    - Data Protection Impact Assessments
    - 72-hour breach notification
  </Tabs.Tab>
</Tabs>

## Technology Stack

<Table>
  <thead>
    <Table.Tr>
      <Table.Th>Component</Table.Th>
      <Table.Th>Technology</Table.Th>
      <Table.Th>Justification</Table.Th>
    </Table.Tr>
  </thead>
  <tbody>
    <Table.Tr>
      <Table.Td>Frontend Framework</Table.Td>
      <Table.Td>Next.js 14 + React</Table.Td>
      <Table.Td>Server components, App Router, TypeScript</Table.Td>
    </Table.Tr>
    <Table.Tr>
      <Table.Td>UI Components</Table.Td>
      <Table.Td>shadcn/ui + Tailwind CSS</Table.Td>
      <Table.Td>Customizable, accessible, modern design</Table.Td>
    </Table.Tr>
    <Table.Tr>
      <Table.Td>State Management</Table.Td>
      <Table.Td>Zustand + React Query</Table.Td>
      <Table.Td>Simple state, server state caching</Table.Td>
    </Table.Tr>
    <Table.Tr>
      <Table.Td>Authentication</Table.Td>
      <Table.Td>Firebase Auth</Table.Td>
      <Table.Td>Multiple providers, secure, scalable</Table.Td>
    </Table.Tr>
    <Table.Tr>
      <Table.Td>User Database</Table.Td>
      <Table.Td>NeonDB (PostgreSQL)</Table.Td>
      <Table.Td>Serverless, branching, auto-scaling</Table.Td>
    </Table.Tr>
    <Table.Tr>
      <Table.Td>ORM</Table.Td>
      <Table.Td>Prisma</Table.Td>
      <Table.Td>Type-safe queries, migrations</Table.Td>
    </Table.Tr>
    <Table.Tr>
      <Table.Td>Deployment</Table.Td>
      <Table.Td>Vercel</Table.Td>
      <Table.Td>Edge network, preview deployments</Table.Td>
    </Table.Tr>
    <Table.Tr>
      <Table.Td>Neural Backend</Table.Td>
      <Table.Td>Python 3.12 + FastAPI</Table.Td>
      <Table.Td>Async performance, BCI ecosystem</Table.Td>
    </Table.Tr>
    <Table.Tr>
      <Table.Td>Real-time Comm</Table.Td>
      <Table.Td>Socket.io + WebSocket</Table.Td>
      <Table.Td>Bidirectional, fallback support</Table.Td>
    </Table.Tr>
    <Table.Tr>
      <Table.Td>Time Series DB</Table.Td>
      <Table.Td>TimescaleDB</Table.Td>
      <Table.Td>PostgreSQL extension, optimized for EEG</Table.Td>
    </Table.Tr>
    <Table.Tr>
      <Table.Td>Caching</Table.Td>
      <Table.Td>Redis</Table.Td>
      <Table.Td>In-memory performance, pub/sub</Table.Td>
    </Table.Tr>
    <Table.Tr>
      <Table.Td>File Storage</Table.Td>
      <Table.Td>Cloud Storage</Table.Td>
      <Table.Td>Object storage for EEG files</Table.Td>
    </Table.Tr>
    <Table.Tr>
      <Table.Td>ML Processing</Table.Td>
      <Table.Td>NumPy + SciPy + MNE</Table.Td>
      <Table.Td>Scientific computing, EEG analysis</Table.Td>
    </Table.Tr>
    <Table.Tr>
      <Table.Td>Monitoring</Table.Td>
      <Table.Td>Vercel Analytics + Sentry</Table.Td>
      <Table.Td>Performance tracking, error monitoring</Table.Td>
    </Table.Tr>
  </tbody>
</Table>

## Deployment Architecture

### Multi-Environment Setup

```mermaid
graph TB
    subgraph "Source Control"
        GH[GitHub Repository]
        GHA[GitHub Actions<br/>CI/CD Pipeline]
    end

    subgraph "Frontend Deployments"
        subgraph "Vercel Platform"
            VP[Preview Deployments<br/>PR Branches]
            VS[Staging<br/>develop branch]
            VPR[Production<br/>main branch]
            VE[Edge Functions<br/>API Routes]
        end
    end

    subgraph "Authentication"
        subgraph "Firebase Projects"
            FB_DEV[Firebase Dev<br/>Test Auth]
            FB_STG[Firebase Staging<br/>UAT Auth]
            FB_PRD[Firebase Production<br/>Live Auth]
        end
    end

    subgraph "Databases"
        subgraph "NeonDB Projects"
            ND_DEV[Neon Dev<br/>Branch Database]
            ND_STG[Neon Staging<br/>Branch Database]
            ND_PRD[Neon Production<br/>Main Database]
        end
    end

    subgraph "Neural Engine"
        subgraph "Development"
            NE_DEV[Local Docker<br/>Hot Reload]
        end
        subgraph "Staging"
            NE_STG[Cloud Run<br/>Staging Instance]
        end
        subgraph "Production"
            NE_PRD[Cloud Run<br/>Production Instances<br/>Auto-scaling]
        end
    end

    subgraph "Storage"
        GCS_DEV[Cloud Storage Dev<br/>Test Data]
        GCS_STG[Cloud Storage Staging<br/>UAT Data]
        GCS_PRD[Cloud Storage Prod<br/>Live Data]
    end

    GH --> GHA
    GHA --> VP
    GHA --> VS
    GHA --> VPR

    VP --> FB_DEV
    VS --> FB_STG
    VPR --> FB_PRD

    VP --> ND_DEV
    VS --> ND_STG
    VPR --> ND_PRD

    VE --> NE_DEV
    VE --> NE_STG
    VE --> NE_PRD

    NE_DEV --> GCS_DEV
    NE_STG --> GCS_STG
    NE_PRD --> GCS_PRD

    style GH fill:#24292e,color:#ffffff
    style GHA fill:#2088fc,color:#ffffff
    style VP fill:#000000,color:#ffffff
    style VS fill:#000000,color:#ffffff
    style VPR fill:#000000,color:#ffffff
    style VE fill:#000000,color:#ffffff
    style FB_DEV fill:#039be5,color:#ffffff
    style FB_STG fill:#fb8c00,color:#ffffff
    style FB_PRD fill:#d32f2f,color:#ffffff
    style ND_DEV fill:#00c896,color:#ffffff
    style ND_STG fill:#00e5a0,color:#000000
    style ND_PRD fill:#00ff88,color:#000000
    style NE_DEV fill:#4285f4,color:#ffffff
    style NE_STG fill:#fbbc04,color:#000000
    style NE_PRD fill:#ea4335,color:#ffffff
```

### Vercel Deployment Pipeline

```mermaid
graph LR
    subgraph "Development Flow"
        DEV[Local Development<br/>npm run dev]
        PR[Pull Request<br/>Feature Branch]
        PD[Preview Deploy<br/>Unique URL]
        REV[Code Review<br/>Testing]
    end

    subgraph "Staging Flow"
        MERGE[Merge to develop]
        STG[Staging Deploy<br/>staging.neurascale.io]
        TEST[Integration Testing<br/>E2E Tests]
    end

    subgraph "Production Flow"
        MAIN[Merge to main]
        PROD[Production Deploy<br/>neurascale.io]
        MON[Monitoring<br/>Analytics]
    end

    DEV --> PR
    PR --> PD
    PD --> REV
    REV --> MERGE
    MERGE --> STG
    STG --> TEST
    TEST --> MAIN
    MAIN --> PROD
    PROD --> MON

    style DEV fill:#0070f3,color:#ffffff
    style PR fill:#0070f3,color:#ffffff
    style PD fill:#000000,color:#ffffff
    style STG fill:#fbbc04,color:#000000
    style PROD fill:#00c896,color:#ffffff
```

## Frontend-Backend Integration

### API Architecture

The console communicates with the Neural Engine through a well-defined API layer that handles authentication, data streaming, and session management.

```mermaid
graph TB
    subgraph "Console (Vercel)"
        C1[Next.js App]
        C2[API Routes<br/>Edge Functions]
        C3[Socket.io Client]
    end

    subgraph "API Gateway"
        AG1[REST Endpoints<br/>/api/v1/*]
        AG2[WebSocket Server<br/>ws://api.neurascale.io]
        AG3[Auth Middleware<br/>Firebase Token Verification]
    end

    subgraph "Neural Engine"
        NE1[Device Controller]
        NE2[Stream Manager]
        NE3[Analysis Pipeline]
    end

    subgraph "Data Flow"
        DF1[Control Commands<br/>Start/Stop/Configure]
        DF2[Real-time Data<br/>EEG Samples @ 250Hz]
        DF3[Analysis Results<br/>Features/Classifications]
    end

    C1 --> C2
    C2 --> AG1
    C3 --> AG2

    AG1 --> AG3
    AG2 --> AG3

    AG3 --> NE1
    AG3 --> NE2
    AG3 --> NE3

    NE1 --> DF1
    NE2 --> DF2
    NE3 --> DF3

    DF1 --> AG1
    DF2 --> AG2
    DF3 --> AG1

    style C1 fill:#0070f3,color:#ffffff
    style C2 fill:#0070f3,color:#ffffff
    style C3 fill:#0070f3,color:#ffffff
    style AG1 fill:#6b7280,color:#ffffff
    style AG2 fill:#6b7280,color:#ffffff
    style AG3 fill:#ffa000,color:#ffffff
```

### Authentication Flow

```mermaid
sequenceDiagram
    participant User
    participant Console
    participant Firebase
    participant NeonDB
    participant API
    participant Neural Engine

    User->>Console: Login Request
    Console->>Firebase: Authenticate with Provider
    Firebase-->>Console: ID Token + User Info
    Console->>NeonDB: Store/Update User Profile
    Console->>API: Request with ID Token
    API->>Firebase: Verify Token
    Firebase-->>API: Token Valid
    API->>Neural Engine: Authorized Request
    Neural Engine-->>API: Response
    API-->>Console: Data
    Console-->>User: Display Results
```

### Disaster Recovery

<Callout type="info">
  **Service-Specific Recovery:**
  - **Vercel**: Automatic failover across global edge network
  - **Firebase**: Multi-region replication, 99.95% SLA
  - **NeonDB**: Point-in-time recovery, branch restoration
  - **Neural Engine**: Multi-instance deployment, health checks
</Callout>

**Backup Strategy:**
- NeonDB: Continuous backups with 7-day retention
- Firebase: Automatic daily backups
- Cloud Storage: Multi-region replication for EEG files
- Configuration: Git-based version control

## Performance Optimization

### Optimization Techniques

<Tabs items={['Zero-Copy', 'SIMD', 'GPU', 'Async I/O']}>
  <Tabs.Tab>
    **Zero-Copy Data Transfer**
    ```python
    # Shared memory segments
    buffer = mmap.mmap(-1, size)
    # Direct memory access
    numpy_array = np.frombuffer(buffer)
    ```
  </Tabs.Tab>

  <Tabs.Tab>
    **SIMD Vectorization**
    ```python
    # NumPy with MKL backend
    # AVX2/AVX-512 instructions
    filtered = np.convolve(data, kernel, mode='same')
    ```
  </Tabs.Tab>

  <Tabs.Tab>
    **GPU Acceleration**
    ```python
    # CuPy for GPU processing
    import cupy as cp
    gpu_data = cp.asarray(cpu_data)
    gpu_fft = cp.fft.fft(gpu_data)
    ```
  </Tabs.Tab>

  <Tabs.Tab>
    **Async I/O**
    ```python
    # AsyncIO for concurrent operations
    async def process_streams(devices):
        tasks = [process_device(d) for d in devices]
        await asyncio.gather(*tasks)
    ```
  </Tabs.Tab>
</Tabs>

## Future Enhancements

### Roadmap

```mermaid
timeline
    title Architecture Evolution Timeline

    section Completed
        Phase 1-8 : Core infrastructure, Real-time processing, Device integration
        Phase 9-12 : GCP migration, Vertex AI integration, Multi-region deployment
        Phase 13-16 : MCP Server, Neural CLI, Production hardening, Security implementation

    section Q1 2026
        Phase 17-18 : Edge deployment, Neural Ledger integration, Advanced ML pipelines

    section Q2 2026
        Phase 19-20 : Federated learning, Privacy-preserving ML, Clinical trials platform

    section Q3 2026
        Phase 21-22 : Neuromorphic computing, Hardware accelerators, Real-time collaboration

    section Q4 2026+
        Phase 23+ : Quantum-ready algorithms, Brain-computer standards, Global platform
```

### Research Areas

- **Neuromorphic Computing** - Brain-inspired hardware integration
- **Spiking Neural Networks** - Event-based processing
- **Reservoir Computing** - Efficient temporal processing
- **Brain-Computer Interface Standards** - Industry standardization

## Related Documentation

- [API Documentation](/api-documentation) - Complete API reference
- [Neural Management System](/neural-management-system) - Neural Engine details
- [Security](/security) - Security and compliance details
- [Contributing Guide](/contributing) - Development guidelines
