# Production Dockerfile for ML Pipeline Service with full ML frameworks
# This version includes TensorFlow and PyTorch for production deployments
# Use the base Dockerfile for CI builds to avoid disk space issues

FROM nvidia/cuda:12.4.1-cudnn9-runtime-ubuntu22.04 AS runtime
# Security updates
RUN apt-get update && apt-get upgrade -y && apt-get install -y --no-install-recommends ca-certificates && rm -rf /var/lib/apt/lists/*

# Install Python 3.12
RUN apt-get update && apt-get install -y --no-install-recommends \
    software-properties-common \
    && add-apt-repository ppa:deadsnakes/ppa \
    && apt-get update && apt-get install -y --no-install-recommends \
    python3.12 \
    python3.12-dev \
    python3.12-venv \
    python3-pip \
    libgomp1 \
    libhdf5-103 \
    libopenblas0 \
    ca-certificates \
    curl \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Set Python 3.12 as default
RUN update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.12 1 \
    && update-alternatives --install /usr/bin/python python /usr/bin/python3.12 1

# Create non-root user
RUN groupadd -r neural && useradd -r -g neural -m neural

# Create app directory
RUN mkdir -p /app/model_cache && chown -R neural:neural /app

WORKDIR /app

# Copy requirements and source
COPY --chown=neural:neural neural-engine/requirements.txt .
COPY --chown=neural:neural neural-engine/src/classification ./classification
COPY --chown=neural:neural neural-engine/src/utils ./utils
COPY --chown=neural:neural neural-engine/src/processors ./processors
COPY --chown=neural:neural neural-engine/models ./models

# Install Python packages as neural user
USER neural

# Create virtual environment
RUN python3 -m venv /app/venv
ENV PATH="/app/venv/bin:$PATH"

# Upgrade pip and install base requirements
RUN pip install --no-cache-dir --upgrade pip setuptools wheel && \
    pip install --no-cache-dir -r requirements.txt

# Install full ML frameworks with CUDA support
RUN pip install --no-cache-dir \
    tensorflow[and-cuda]==2.15.0 \
    torch==2.1.2+cu121 \
    torchvision==0.16.2+cu121 \
    torchaudio==2.1.2+cu121 \
    -f https://download.pytorch.org/whl/torch_stable.html

# Install additional ML packages
RUN pip install --no-cache-dir \
    scikit-learn==1.4.0 \
    xgboost==2.0.3 \
    joblib==1.3.2 \
    pandas==2.1.4 \
    numpy==1.26.4 \
    scipy==1.14.1 \
    transformers==4.36.2 \
    lightning==2.1.3

# Environment variables for ML frameworks
ENV TF_CPP_MIN_LOG_LEVEL=2 \
    OMP_NUM_THREADS=4 \
    OPENBLAS_NUM_THREADS=4 \
    MKL_NUM_THREADS=4 \
    CUDA_VISIBLE_DEVICES=0 \
    TF_FORCE_GPU_ALLOW_GROWTH=true

# Create startup script
RUN echo '#!/bin/sh\npython -m classification.api --host 0.0.0.0 --port 8080' > /app/entrypoint.sh && \
    chmod +x /app/entrypoint.sh

# Expose ports
EXPOSE 8080 50051

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:8080/health || exit 1

# Run the service
ENTRYPOINT ["/app/entrypoint.sh"]
