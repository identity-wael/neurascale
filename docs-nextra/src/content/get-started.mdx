import { Steps, Tabs, Callout } from 'nextra/components'

# Get Started

This guide will help you get up and running with NeuraScale in minutes.

## Prerequisites

Before you begin, ensure you have the following installed:

### Core Requirements
- **Python** 3.12.11 (exact version required) - [Download](https://www.python.org/downloads/)
- **Node.js** 18.x or higher - [Download](https://nodejs.org/)
- **pnpm** 9.x or higher - [Installation guide](https://pnpm.io/installation)
- **Docker** & Docker Compose - [Download](https://www.docker.com/)
- **Git** - [Download](https://git-scm.com/)

### For Console Development
- **Firebase CLI** - [Installation guide](https://firebase.google.com/docs/cli)
- **Vercel CLI** - [Installation guide](https://vercel.com/docs/cli)
- **Neon CLI** (optional) - [Installation guide](https://neon.tech/docs/reference/cli-install)

### For GCP Deployment
- **Google Cloud SDK** - [Installation guide](https://cloud.google.com/sdk/docs/install)
- **Terraform** 1.5.x or higher - [Download](https://www.terraform.io/downloads)
- **kubectl** - [Installation guide](https://kubernetes.io/docs/tasks/tools/)
- **Helm** 3.x - [Installation guide](https://helm.sh/docs/intro/install/)

<Callout type="warning">
  Python version must be exactly 3.12.11. Other versions may cause compatibility issues.
</Callout>

### GCP Setup

<Steps>
### Install Google Cloud SDK

<Tabs items={['macOS', 'Linux', 'Windows']}>
  <Tabs.Tab>
    ```bash
    # Using Homebrew
    brew install --cask google-cloud-sdk

    # Or download from https://cloud.google.com/sdk/docs/install
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```bash
    # Add the Cloud SDK distribution URI as a package source
    echo "deb [signed-by=/usr/share/keyrings/cloud.google.gpg] https://packages.cloud.google.com/apt cloud-sdk main" | sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list

    # Import the Google Cloud public key
    curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key --keyring /usr/share/keyrings/cloud.google.gpg add -

    # Update and install the SDK
    sudo apt-get update && sudo apt-get install google-cloud-cli
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    Download and run the installer from: https://cloud.google.com/sdk/docs/install#windows
  </Tabs.Tab>
</Tabs>

### Authenticate with GCP

```bash
# Login to GCP
gcloud auth login

# Set default project (use your environment)
gcloud config set project development-neurascale

# Configure application default credentials
gcloud auth application-default login
```

### Install Terraform

<Tabs items={['macOS', 'Linux', 'Windows']}>
  <Tabs.Tab>
    ```bash
    # Using Homebrew
    brew install terraform

    # Verify installation
    terraform --version
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```bash
    # Add HashiCorp GPG key
    wget -O- https://apt.releases.hashicorp.com/gpg | sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg

    # Add HashiCorp repo
    echo "deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main" | sudo tee /etc/apt/sources.list.d/hashicorp.list

    # Install Terraform
    sudo apt update && sudo apt install terraform
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    Download from: https://www.terraform.io/downloads

    Or use Chocolatey:
    ```powershell
    choco install terraform
    ```
  </Tabs.Tab>
</Tabs>

### Configure GCP Permissions

Ensure your GCP account has the following roles:
- `roles/owner` or `roles/editor` for development
- `roles/iam.serviceAccountUser` for service account impersonation
- `roles/storage.admin` for Terraform state management

For production deployments, use the service account:
```bash
gcloud iam service-accounts keys create ~/key.json \
  --iam-account=github-actions@neurascale.iam.gserviceaccount.com

export GOOGLE_APPLICATION_CREDENTIALS=~/key.json
```
</Steps>

## Firebase Setup

<Steps>
### Install Firebase CLI

<Tabs items={['npm', 'standalone']}>
  <Tabs.Tab>
    ```bash
    npm install -g firebase-tools

    # Verify installation
    firebase --version
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```bash
    # Download the standalone binary
    curl -sL https://firebase.tools | bash
    ```
  </Tabs.Tab>
</Tabs>

### Initialize Firebase Project

```bash
# Login to Firebase
firebase login

# Initialize Firebase in the console directory
cd console
firebase init
```

Select the following services:
- **Authentication** - For user management
- **Hosting** - For Vercel integration (optional)
- **Functions** - For server-side auth operations

### Configure Firebase Authentication

1. Go to [Firebase Console](https://console.firebase.google.com)
2. Select your project or create a new one
3. Navigate to **Authentication** â†’ **Sign-in method**
4. Enable the following providers:
   - Email/Password
   - Google
   - GitHub (optional)

### Set up Environment Variables

Create `.env.local` in the console directory:

```env
# Firebase Configuration
NEXT_PUBLIC_FIREBASE_API_KEY=your-api-key
NEXT_PUBLIC_FIREBASE_AUTH_DOMAIN=your-auth-domain
NEXT_PUBLIC_FIREBASE_PROJECT_ID=your-project-id
NEXT_PUBLIC_FIREBASE_STORAGE_BUCKET=your-storage-bucket
NEXT_PUBLIC_FIREBASE_MESSAGING_SENDER_ID=your-sender-id
NEXT_PUBLIC_FIREBASE_APP_ID=your-app-id

# Firebase Admin SDK (for API routes)
FIREBASE_ADMIN_PROJECT_ID=your-project-id
FIREBASE_ADMIN_CLIENT_EMAIL=your-client-email
FIREBASE_ADMIN_PRIVATE_KEY=your-private-key
```
</Steps>

## NeonDB Setup

<Steps>
### Create Neon Account

1. Sign up at [neon.tech](https://neon.tech)
2. Create a new project for NeuraScale
3. Choose your region (preferably same as GCP region)

### Configure Database Connection

Get your connection string from the Neon dashboard and add to `.env.local`:

```env
# NeonDB Configuration
DATABASE_URL=postgresql://user:password@host/neurascale?sslmode=require
DIRECT_URL=postgresql://user:password@host/neurascale?sslmode=require
```

### Initialize Database Schema

```bash
cd console

# Install Prisma CLI
pnpm add -D prisma @prisma/client

# Initialize Prisma
npx prisma init

# Push schema to database
npx prisma db push

# Generate Prisma client
npx prisma generate
```

### Set up Database Branching (Optional)

For development workflows:

```bash
# Install Neon CLI
npm install -g neonctl

# Authenticate
neonctl auth

# Create a development branch
neonctl branches create --name dev --project-id your-project-id
```
</Steps>

## Quick Start

<Steps>
### Clone the Repository

```bash
git clone https://github.com/identity-wael/neurascale.git
cd neurascale
```

### Set Up Virtual Environments

Run our automated setup script to configure Python environments:

```bash
./scripts/dev-tools/setup-venvs.sh
```

This script will:
- Verify Python 3.12.11 is available
- Create virtual environments for all components
- Install required dependencies

### Start Infrastructure Services

Choose your deployment method:

**Local Development**

Launch the required infrastructure services locally:

```bash
docker-compose up -d
```

This starts:
- TimescaleDB for time-series data
- Redis for caching and real-time features
- PostgreSQL for application data
- MCP Server for AI assistant integration

**GCP Deployment**

For production GCP deployment, we use a multi-environment Terraform setup:

```bash
cd neural-engine/terraform

# Initialize with environment-specific backend
terraform init -backend-config=backend-configs/development.hcl

# Plan with environment variables
terraform plan -var-file="environments/development.tfvars"

# Apply infrastructure
terraform apply -var-file="environments/development.tfvars"
```

**GCP Resources Created:**
- **Bigtable**: For high-performance time-series neural data storage
- **Pub/Sub**: Topics and subscriptions for each signal type (EEG, EMG, etc.)
- **Cloud Run**: MCP Server deployment
- **Artifact Registry**: Docker image storage
- **Cloud SQL**: PostgreSQL for metadata and session data
- **Secret Manager**: API keys and sensitive configuration
- **GKE**: Kubernetes cluster for Neural Engine (production only)

### Start the Neural Engine

<Tabs items={['Development', 'Staging', 'Production']}>
  <Tabs.Tab>
    ```bash
    cd neural-engine
    source venv/bin/activate
    python -m src.main
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```bash
    cd neural-engine
    source venv/bin/activate
    # Configure for staging environment
    export ENV=staging
    export GCP_PROJECT=staging-neurascale
    uvicorn src.main:app --host 0.0.0.0 --port 8000 --workers 2
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```bash
    cd neural-engine
    source venv/bin/activate
    # Configure for production environment
    export ENV=production
    export GCP_PROJECT=production-neurascale
    uvicorn src.main:app --host 0.0.0.0 --port 8000 --workers 4
    ```
  </Tabs.Tab>
</Tabs>

The Neural Engine API will be available at: http://localhost:8000

### Start the Console

The NeuraScale Console provides a web interface for device management and data visualization.

<Tabs items={['Local Development', 'Production']}>
  <Tabs.Tab>
    ```bash
    cd console

    # Install dependencies
    pnpm install

    # Run database migrations
    npx prisma migrate dev

    # Start development server
    pnpm dev
    ```

    The console will be available at: http://localhost:3000
  </Tabs.Tab>
  <Tabs.Tab>
    ```bash
    cd console

    # Build for production
    pnpm build

    # Deploy to Vercel
    vercel --prod
    ```

    Follow the prompts to deploy to your Vercel account.
  </Tabs.Tab>
</Tabs>

**Console Features:**
- Real-time device monitoring
- EEG data visualization
- Session recording and playback
- User authentication via Firebase
- Experiment management

### Test Your Installation

Create a synthetic device to verify everything is working:

```bash
# Create a test device
curl -X POST http://localhost:8000/api/v1/devices \
  -H "Content-Type: application/json" \
  -d '{"device_id": "test-device", "device_type": "synthetic"}'

# Start streaming data
curl -X POST http://localhost:8000/api/v1/devices/test-device/stream/start
```

You should see synthetic neural data streaming in the logs.
</Steps>

## Deployment Environments

NeuraScale uses a multi-environment GCP setup:

| Environment | Project ID | Branch | Purpose |
|------------|------------|--------|---------|
| Development | `development-neurascale` | `develop` | Feature development and testing |
| Staging | `staging-neurascale` | PR branches | Integration testing and validation |
| Production | `production-neurascale` | `main` | Live production environment |

Each environment has:
- Isolated GCP project with separate billing
- Environment-specific Terraform state in GCS
- Automated deployment via GitHub Actions
- Cross-project IAM for service accounts

## Project Structure

```
neurascale/
â”œâ”€â”€ neural-engine/           # Core neural data processing engine
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/            # FastAPI endpoints
â”‚   â”‚   â”œâ”€â”€ devices/        # Device interfaces (OpenBCI, Emotiv, etc.)
â”‚   â”‚   â”œâ”€â”€ processing/     # Signal processing pipelines
â”‚   â”‚   â”œâ”€â”€ classification/ # Real-time ML models
â”‚   â”‚   â””â”€â”€ neural_ledger/  # HIPAA-compliant audit trail
â”‚   â”œâ”€â”€ terraform/          # GCP infrastructure as code
â”‚   â”‚   â”œâ”€â”€ modules/        # Reusable Terraform modules
â”‚   â”‚   â”‚   â”œâ”€â”€ neural-ingestion/  # Pub/Sub, Bigtable, Cloud Functions
â”‚   â”‚   â”‚   â”œâ”€â”€ mcp-server/        # Cloud Run MCP deployment
â”‚   â”‚   â”‚   â”œâ”€â”€ networking/        # VPC and service connections
â”‚   â”‚   â”‚   â”œâ”€â”€ gke/              # Kubernetes cluster config
â”‚   â”‚   â”‚   â””â”€â”€ database/          # Cloud SQL, Redis, BigQuery
â”‚   â”‚   â”œâ”€â”€ environments/   # Environment-specific configs
â”‚   â”‚   â””â”€â”€ backend-configs/# Terraform state backends
â”‚   â””â”€â”€ tests/              # Test suite
â”œâ”€â”€ console/                # NeuraScale Console UI
â”œâ”€â”€ docs-nextra/           # Documentation (you are here!)
â”œâ”€â”€ infrastructure/        # Kubernetes & deployment configs
â”‚   â”œâ”€â”€ cross-project-iam/ # IAM setup across GCP projects
â”‚   â””â”€â”€ k8s/              # Kubernetes manifests
â”œâ”€â”€ kubernetes/            # Helm charts
â”‚   â””â”€â”€ helm/neural-engine/# Neural Engine Helm chart
â”œâ”€â”€ mcp-server/           # Model Context Protocol server
â””â”€â”€ scripts/              # Development tools and utilities
```

## Next Steps

Now that you have NeuraScale running, explore:

<div className="nx-grid nx-mt-6 nx-gap-4 md:nx-grid-cols-2">
  <div className="nx-border nx-border-gray-200 dark:nx-border-gray-800 nx-rounded-lg nx-p-4">
    <h3 className="nx-font-semibold nx-mb-2">Connect a Device</h3>
    <div className="nx-text-sm nx-text-gray-600 dark:nx-text-gray-400 nx-mb-2">
      Learn how to connect real BCI devices
    </div>
    <a href="/docs/device-integration" className="nx-text-primary-600 nx-text-sm">
      Device Integration â†’
    </a>
  </div>

  <div className="nx-border nx-border-gray-200 dark:nx-border-gray-800 nx-rounded-lg nx-p-4">
    <h3 className="nx-font-semibold nx-mb-2">Build Your First App</h3>
    <div className="nx-text-sm nx-text-gray-600 dark:nx-text-gray-400 nx-mb-2">
      Create a simple BCI application
    </div>
    <a href="/docs/tutorials/first-app" className="nx-text-primary-600 nx-text-sm">
      Tutorial â†’
    </a>
  </div>

  <div className="nx-border nx-border-gray-200 dark:nx-border-gray-800 nx-rounded-lg nx-p-4">
    <h3 className="nx-font-semibold nx-mb-2">API Reference</h3>
    <div className="nx-text-sm nx-text-gray-600 dark:nx-text-gray-400 nx-mb-2">
      Explore the complete API documentation
    </div>
    <a href="/docs/api" className="nx-text-primary-600 nx-text-sm">
      API Docs â†’
    </a>
  </div>

  <div className="nx-border nx-border-gray-200 dark:nx-border-gray-800 nx-rounded-lg nx-p-4">
    <h3 className="nx-font-semibold nx-mb-2">Architecture Deep Dive</h3>
    <div className="nx-text-sm nx-text-gray-600 dark:nx-text-gray-400 nx-mb-2">
      Understand the system architecture
    </div>
    <a href="/docs/architecture" className="nx-text-primary-600 nx-text-sm">
      Architecture â†’
    </a>
  </div>
</div>

## Common Commands

<Tabs items={['Neural Engine', 'Neural CLI', 'Development', 'Docker']}>
  <Tabs.Tab>
    ```bash
    # Activate virtual environment
    source neural-engine/venv/bin/activate

    # Start the engine
    python -m src.main

    # Run tests
    pytest tests/

    # Format code
    black .

    # Lint code
    flake8 .

    # Type checking
    mypy .
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```bash
    # Using Docker
    docker run --rm --network neural-engine_neural-net \
      neurascale/neural-cli:latest list-devices

    # List active streams
    docker run --rm --network neural-engine_neural-net \
      neurascale/neural-cli:latest list-streams

    # Monitor device
    docker run --rm --network neural-engine_neural-net \
      neurascale/neural-cli:latest monitor --device-id test-device

    # View audit trail
    docker run --rm --network neural-engine_neural-net \
      neurascale/neural-cli:latest audit --last 100
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```bash
    # Install dependencies
    pnpm install

    # Start development server
    pnpm dev

    # Build for production
    pnpm build

    # Run linting
    pnpm lint

    # Format code
    pnpm format
    ```
  </Tabs.Tab>
  <Tabs.Tab>
    ```bash
    # Start all services
    docker-compose up -d

    # View logs
    docker-compose logs -f

    # Stop services
    docker-compose down

    # Clean volumes
    docker-compose down -v

    # Deploy to GKE using Helm
    helm upgrade --install neural-engine \
      kubernetes/helm/neural-engine/ \
      --values kubernetes/helm/neural-engine/values.yaml \
      --namespace neural-engine \
      --create-namespace
    ```
  </Tabs.Tab>
</Tabs>

## Troubleshooting

<Callout type="error" title="Port Already in Use">
  If you see "Port 3000/8000 is already in use":

  ```bash
  # Find and kill the process
  lsof -ti:3000 | xargs kill -9
  # Or use a different port
  PORT=3001 npm run dev
  ```
</Callout>

<Callout type="error" title="Python Version Issues">
  If you encounter Python version errors:

  ```bash
  # Check your Python version
  python --version

  # Must be exactly 3.12.11
  # Run the setup script to fix
  ./scripts/dev-tools/setup-venvs.sh
  ```
</Callout>

<Callout type="info">
  For more troubleshooting help, see our [Troubleshooting Guide](/docs/troubleshooting) or ask in [GitHub Discussions](https://github.com/identity-wael/neurascale/discussions).
</Callout>

## Getting Help

- **Documentation**: [docs.neurascale.io](https://docs.neurascale.io)
- **GitHub Discussions**: [Ask questions](https://github.com/identity-wael/neurascale/discussions)
- **Issue Tracker**: [Report bugs](https://github.com/identity-wael/neurascale/issues)
- **Email Support**: [support@neurascale.io](mailto:support@neurascale.io)

Ready to build something amazing? Let's bridge mind and world together!
