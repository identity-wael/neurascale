name: Neural Engine CI/CD

on:
  push:
    branches: [main, develop]
    paths:
      - 'neural-engine/**'
      - '.github/workflows/neural-engine-ci.yml'
  pull_request:
    branches: [main]
    paths:
      - 'neural-engine/**'
      - '.github/workflows/neural-engine-ci.yml'

env:
  PYTHON_VERSION: '3.12'
  GCP_PROJECT_ID: neurascale
  GCP_REGION: northamerica-northeast1
  ARTIFACT_REGISTRY: northamerica-northeast1-docker.pkg.dev
  REPOSITORY_NAME: neural-engine

jobs:
  test:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: neural-engine

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Cache pip dependencies
      uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('neural-engine/requirements*.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt
        pip install -e .

    - name: Run linting
      run: |
        python -m black --check src/ tests/ examples/
        python -m flake8 src/ tests/ examples/ --max-line-length=88 --extend-ignore=E203

    - name: Run type checking
      run: |
        python -m mypy src/ --ignore-missing-imports

    - name: Run unit tests
      run: |
        python -m pytest tests/unit/test_ingestion/ -v --cov=src/ingestion --cov-report=xml

    - name: Upload coverage
      uses: codecov/codecov-action@v4
      with:
        file: ./neural-engine/coverage.xml
        flags: neural-engine
        name: neural-engine-coverage

  build-docker:
    needs: test
    runs-on: ubuntu-latest
    if: github.event_name == 'push'

    steps:
    - uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Authenticate to Google Cloud
      uses: google-github-actions/auth@v2
      with:
        workload_identity_provider: ${{ secrets.WIF_PROVIDER }}
        service_account: ${{ secrets.WIF_SERVICE_ACCOUNT }}

    - name: Configure Docker for Artifact Registry
      run: |
        gcloud auth configure-docker ${{ env.ARTIFACT_REGISTRY }}

    - name: Build and push Docker image
      uses: docker/build-push-action@v6
      with:
        context: ./neural-engine
        file: ./neural-engine/docker/Dockerfile.ingestion
        push: true
        tags: |
          ${{ env.ARTIFACT_REGISTRY }}/${{ env.GCP_PROJECT_ID }}/${{ env.REPOSITORY_NAME }}/ingestion:${{ github.sha }}
          ${{ env.ARTIFACT_REGISTRY }}/${{ env.GCP_PROJECT_ID }}/${{ env.REPOSITORY_NAME }}/ingestion:latest
        cache-from: type=gha
        cache-to: type=gha,mode=max

  terraform-plan:
    needs: test
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    defaults:
      run:
        working-directory: neural-engine/terraform/ingestion

    steps:
    - uses: actions/checkout@v4

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: 1.6.0

    - name: Authenticate to Google Cloud
      uses: google-github-actions/auth@v2
      with:
        workload_identity_provider: ${{ secrets.WIF_PROVIDER }}
        service_account: ${{ secrets.WIF_SERVICE_ACCOUNT }}

    - name: Terraform Init
      run: terraform init

    - name: Terraform Format Check
      run: terraform fmt -check

    - name: Terraform Plan
      run: |
        terraform plan -var="project_id=${{ env.GCP_PROJECT_ID }}" \
                      -var="region=${{ env.GCP_REGION }}" \
                      -var="environment=development" \
                      -out=tfplan

    - name: Upload Terraform Plan
      uses: actions/upload-artifact@v4
      with:
        name: tfplan
        path: neural-engine/terraform/ingestion/tfplan

  deploy-infrastructure:
    needs: [build-docker]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    defaults:
      run:
        working-directory: neural-engine/terraform/ingestion

    steps:
    - uses: actions/checkout@v4

    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: 1.6.0

    - name: Authenticate to Google Cloud
      uses: google-github-actions/auth@v2
      with:
        workload_identity_provider: ${{ secrets.WIF_PROVIDER }}
        service_account: ${{ secrets.WIF_SERVICE_ACCOUNT }}

    - name: Terraform Init
      run: terraform init

    - name: Terraform Apply
      run: |
        terraform apply -var="project_id=${{ env.GCP_PROJECT_ID }}" \
                       -var="region=${{ env.GCP_REGION }}" \
                       -var="environment=production" \
                       -auto-approve

  integration-test:
    needs: [deploy-infrastructure]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: ${{ env.PYTHON_VERSION }}

    - name: Authenticate to Google Cloud
      uses: google-github-actions/auth@v2
      with:
        workload_identity_provider: ${{ secrets.WIF_PROVIDER }}
        service_account: ${{ secrets.WIF_SERVICE_ACCOUNT }}

    - name: Install dependencies
      working-directory: neural-engine
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -e .

    - name: Run integration tests
      working-directory: neural-engine
      run: |
        # Test Pub/Sub publishing
        python -c "
        import json
        from google.cloud import pubsub_v1

        publisher = pubsub_v1.PublisherClient()
        topic_path = publisher.topic_path('${{ env.GCP_PROJECT_ID }}', 'neural-data-eeg')

        test_message = {
            'device_id': 'test_device',
            'device_type': 'test',
            'signal_type': 'eeg',
            'source': 'synthetic',
            'session_id': 'test_session',
            'timestamp': '2024-01-01T12:00:00Z',
            'sampling_rate': 256.0,
            'data': [[0.0] * 256] * 8,
            'channels': [{'channel_id': i, 'label': f'Ch{i+1}'} for i in range(8)]
        }

        future = publisher.publish(topic_path, json.dumps(test_message).encode())
        print(f'Published message ID: {future.result()}')
        "

    - name: Check Cloud Function logs
      run: |
        sleep 30  # Wait for function to process
        gcloud functions logs read process-neural-stream \
          --region=${{ env.GCP_REGION }} \
          --limit=50 \
          --format="table(time,text)"
